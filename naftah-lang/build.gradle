import java.time.LocalDateTime
import java.time.format.DateTimeFormatter

plugins {
	id 'antlr'
	id 'jacoco'
	id 'maven-publish'
	id 'signing'
}

tasks.withType(JavaCompile).configureEach {
	options.compilerArgs += [
			'--enable-preview',
			'--add-modules', 'jdk.incubator.vector'
	]
}

dependencies {
	implementation project(':naftah-builtin-core')
	antlr "org.antlr:antlr4:4.9.3"
	implementation "org.antlr:antlr4-runtime:4.9.3"
	checkstyle 'com.puppycrawl.tools:checkstyle:10.0'
	implementation 'info.picocli:picocli:4.7.6'
	implementation 'org.jline:jline:3.23.0'
	implementation 'org.jline:jline-terminal-jansi:3.28.0'
	implementation 'org.openjdk.jmh:jmh-core:1.37'
	implementation('com.vladsch.flexmark:flexmark:0.64.0') {
		exclude group: 'com.vladsch.flexmark', module: 'flexmark-util-html'
	}
	annotationProcessor 'org.openjdk.jmh:jmh-generator-annprocess:1.37'
}

generateGrammarSource {
	maxHeapSize = "128m"
	arguments += ['-encoding', 'UTF-8', '-package', 'org.daiitech.naftah.parser', '-visitor', '-no-listener']
}

compileJava.dependsOn generateGrammarSource

sourceSets {
	generated {
		java.srcDir 'generated-src/antlr/main/'
	}

	benchmark {
		java.srcDir 'benchmark/java'
		resources.srcDir 'benchmark/resources'
		compileClasspath += sourceSets.main.output + configurations.annotationProcessor
		runtimeClasspath += output + compileClasspath
	}
}

compileJava.source sourceSets.generated.java, sourceSets.main.java

clean {
	delete "generated-src"
}

idea {
	module {
		sourceDirs += file("generated-src/antlr/main/")
	}
}

tasks.register('copyJavadoc', Copy) {
	dependsOn javadoc
	from javadoc.destinationDir
	into "$rootDir/docs-site/javadoc"
}

tasks.register('extractLexerLiterals') {
	description = 'Extracts all literal strings from lexer grammar rules.'

	def lexerFile = file('src/main/antlr/NaftahLexer.g4')
	def outputFile = layout.buildDirectory.file("libs/lexer-literals").get().asFile

	def tokensFile = layout.buildDirectory.file("libs/tokens-symbols.properties").get().asFile

	doLast {
		// literals processing
		def literalsPattern = ~/'([^']+)'/
		def literals = []
		// tokens list processing
		def tokensPattern = ~/^(\w+)\s*:\s*((?:'[^']+'\s*\|\s*)*'[^']+')\s*;$/
		def tokensAndPlaceholderPattern = ~/^(\w+)\s*:\s*((?:('[^']+'|.+)\s*\|\s*)*('[^']+'|.+))\s*;$/
		def skipPatterns = [
				~/^\s*fragment\s*.*/,
				~/.*\s*skip\s*.*/,
				~/^\s*WS\s*:\s*.*/,
				~/^\s*LINE_COMMENT\s*:\s*.*/,
				~/^\s*BLOCK_COMMENT\s*:\s*.*/,
				~/^\s*QuotationMark\s*:\s*.*/,
				~/^\s*DoubleQuotationMark\s*:\s*.*/,
				~/^\s*DoubleQuotationMarkLeft\s*:\s*.*/,
				~/^\s*DoubleQuotationMarkRight\s*:\s*.*/,
				~/^\s*\/\/.*$/,      // skip comment lines starting with //
				~/^\s*$/,            // skip empty lines
		]

		def literalPatterns = [
				~/^\s*NUMBER\s*:\s*.*/,
				~/^\s*BASE_DIGITS\s*:\s*.*/,
				~/^\s*BASE_RADIX\s*:\s*.*/,
				~/^\s*CHARACTER\s*:\s*.*/,
				~/^\s*STRING\s*:\s*.*/,
				~/^\s*ID\s*:\s*.*/,
				~/^\s*PUNCTUATION\s*:\s*.*/
		]

		def literalTranslations = [
				"NUMBER"     : "Ø±Ù‚Ù…",
				"BASE_DIGITS": "Ø±Ù‚Ù…_Ø§Ù„Ø£Ø³Ø§Ø³",
				"BASE_RADIX" : "Ù†Ø¸Ø§Ù…_Ø§Ù„Ø¹Ø¯",
				"CHARACTER"  : "Ø­Ø±Ù",
				"STRING"     : "Ø³Ù„Ø³Ù„Ø©",
				"ID"         : "Ù…Ø¹Ø±Ù",
				"PUNCTUATION": "ØªØ±Ù‚ÙŠÙ…"
		]
		def tokens = new Properties()

		lexerFile.withReader('UTF-8') { reader ->
			//noinspection GroovyMissingReturnStatement
			reader.eachLine { line ->
				// processing literals
				if (line.contains(":")) {
					literalsPattern.matcher(line).each { match ->
						literals << match[1]
					}
				}
				// processing tokens list
				// Skip lines matching any skip pattern
				boolean toSkip = skipPatterns.any { skipPattern -> line ==~ skipPattern }
				if (toSkip) {
					return
				}
				// Check for matching literal patterns and print Arabic translation
				boolean isLiteral = literalPatterns.any { literalPattern ->
					if (line ==~ literalPattern) {
						// Extract the key (e.g., NUMBER) from the line using regex
						def matcher = (line =~ /^\s*(\w+)\s*:/)
						if (matcher.find()) {
							def token = matcher.group(1)
							def symbol = literalTranslations[token]
							tokens.setProperty(token, "'${symbol}'")
						}
						return true
					}
					return false
				}

				if (!isLiteral) {

					def matcher = line =~ tokensPattern

					if (matcher.matches()) {
						//noinspection GroovyAssignabilityCheck
						String token = matcher[0][1]
						//noinspection GroovyAssignabilityCheck
						def tokensGroup = matcher[0][2]

						// Extract all quoted tokens
						def symbols = []
						(tokensGroup =~ literalsPattern).each { match ->
							symbols << match[0]
						}
						tokens.setProperty(token, symbols.join(", "))
					} else {
						def tokensAndPlaceholderMatcher = line =~ tokensAndPlaceholderPattern
						if (tokensAndPlaceholderMatcher.matches()) {
							//noinspection GroovyAssignabilityCheck
							String token = tokensAndPlaceholderMatcher[0][1]
							//noinspection GroovyAssignabilityCheck
							def tokensGroup = tokensAndPlaceholderMatcher[0][2]

							// Extract all quoted tokens
							def symbols = []

							(tokensGroup =~ literalsPattern).each { match ->
								symbols << match[0]
							}

							//noinspection GroovyAssignabilityCheck
							def placeholderParts = tokensGroup.split(/\s*\|\s*/).findAll { part ->
								!(part =~ literalsPattern)
							}

							placeholderParts.each { placeholderPart ->
								// Split tokens by whitespace (since no pipes here)
								//noinspection GroovyAssignabilityCheck
								def symbolsList = placeholderPart.split(/\s+/).collect { "PLACEHOLDER(${it.trim()})" }

								// Remove single quotes if any (none here but safe)
								symbolsList = symbolsList.collect { it.replaceAll(/^'(.*)'$/, '$1') }

								symbols << symbolsList.join(" ")
							}

							tokens.setProperty(token, symbols.join(", "))
						}
					}
				}
			}
		}

		outputFile.parentFile.mkdirs()
		outputFile.withWriter('UTF-8') { writer ->
			literals.each { //noinspection GroovyAssignabilityCheck
				writer.writeLine(it)
			}
		}

		tokensFile.withOutputStream { stream ->
			tokens.store(stream, "tokens symbols list extracted from lexer.")
		}

		println "Extracted ${literals.size()} literals to ${outputFile}"
	}
}

tasks.register('writeResolvedJars') {
	description = 'Writes resolved JAR file names to build/libs/original-dependencies'

	doLast {
		def outputFile = layout.buildDirectory.file("libs/original-dependencies").get().asFile
		outputFile.text = ""

		configurations.runtimeClasspath.resolvedConfiguration.resolvedArtifacts.each { artifact ->
			def jarName = artifact.file.name
			outputFile << jarName + "\n"
		}

		println "Dependencies written to: ${outputFile}"
	}
}

jacoco {
	toolVersion = "0.8.10"
}

test {
	testLogging {
		events "passed", "skipped", "failed"
	}
	finalizedBy jacocoTestReport, jacocoTestCoverageVerification
}

jacocoTestReport {
	dependsOn test
	reports {
		xml.required = true
		html.required = true
		csv.required = false
	}
}

jacocoTestCoverageVerification {
	dependsOn test
	violationRules {
		rule {
			enabled = false
			element = 'CLASS'
			limit {
				counter = 'LINE'
				value = 'COVEREDRATIO'
				minimum = 0.70 // 70% coverage threshold
			}
		}
		rule {
			enabled = true
			element = 'BUNDLE'
			limit {
				counter = 'LINE'
				value = 'COVEREDRATIO'
				minimum = 0.70 // 70% coverage threshold
			}
		}
	}
}

tasks.named("spotlessJava").configure {
	dependsOn tasks.named("generateGrammarSource")
}

// This task formats the code, but doesn't run on build by default
tasks.register('format') {
	group = 'formatting'
	description = 'Formats all Java source files.'

	dependsOn 'spotlessApply'
}
check.dependsOn checkstyleMain, checkstyleTest, checkstyleBenchmark

// lint + format in one custom task
tasks.register('lintAndFormat') {
	group = 'verification'
	description = 'Run checkstyle lint and auto-format code.'

	dependsOn checkstyleMain, checkstyleTest, checkstyleBenchmark, spotlessApply
}

tasks.register('generateReleasePropertiesFile') {
	doLast {
		def outputFile = layout.buildDirectory.file("resources/main/META-INF/naftah-release-info.properties").get().asFile

		// Create properties file and set properties
		outputFile.parentFile.mkdirs()  // Create the META-INF directory if it doesn't exist

		def buildDate = LocalDateTime.now()

		def date = buildDate.format(DateTimeFormatter.ofPattern('dd-MMM-yyyy'))
		def time = buildDate.format(DateTimeFormatter.ofPattern('hh:mm:ss'))

		outputFile.withWriter('utf-8') {
			it.write("""#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.
#

ImplementationVersion=${version}
BundleVersion=${version}
BuildDate=$date
BuildTime=$time
Class-Path= ${configurations.runtimeClasspath
					.files
					.collect { "lib/${it.name}" }
					.join(' ')
			}
""")
		}
	}
}

processResources.dependsOn generateReleasePropertiesFile

jar {
	manifest {
		attributes(
				'Main-Class': 'org.daiitech.naftah.Naftah',
				'Implementation-Title': 'NAFTAH',
				'Implementation-Version': project.version,
				'Implementation-Vendor': 'DaiiTech',
				'Built-By': System.getProperty('user.name'),
				'Built-Date': LocalDateTime.now().format("yyyy-MM-dd'T'HH:mm"),
				// ðŸ‘‡ Class-Path attribute (relative paths to JARs in /lib/)
				'Class-Path': configurations.runtimeClasspath
						.files
						.collect { "lib/${it.name}" }
						.join(' ')
		)
	}
}

// Task to copy dependencies to /build/libs/lib/
tasks.register('copyDependencies', Copy) {
	from configurations.runtimeClasspath
	into layout.buildDirectory.file("libs/lib").get().asFile
}

jar.dependsOn processResources
jar.finalizedBy copyDependencies

tasks.register('fatJar', Jar) {
	archiveBaseName = "${project.name}-standalone"
	destinationDirectory.set(layout.buildDirectory.file("libs/").get().asFile)
	manifest {
		attributes(
				'Main-Class': 'org.daiitech.naftah.Naftah',
				'Implementation-Title': 'NAFTAH',
				'Implementation-Version': project.version,
				'Implementation-Vendor': 'DaiiTech',
				'Built-By': System.getProperty('user.name'),
				'Built-Date': LocalDateTime.now().format("yyyy-MM-dd'T'HH:mm")
		)
	}
	duplicatesStrategy = DuplicatesStrategy.EXCLUDE

	from {
		configurations.runtimeClasspath.collect { it.isDirectory() ? it : zipTree(it) }
	}
	with jar
}

def zipBaseFolder = 'naftah'

tasks.register('baseDistZip', Zip) {
	// Set the name of the output zip file
	destinationDirectory.set(layout.buildDirectory.file("distributions").get().asFile)
	archiveBaseName.set("${project.name}")

	from('../.') {
		include 'INSTALL', 'LICENSE'
		into zipBaseFolder
	}

	from('src/main/bin') {
		into "${zipBaseFolder}/bin"
	}

	from('../learn-by-example') {
		into "${zipBaseFolder}/learn-by-example"
	}

	from('../docs-site/_includes/language') {
		into "${zipBaseFolder}/manual"
	}

	from(layout.buildDirectory.file("libs").get().asFile) {
		include 'lexer-literals', 'original-dependencies', 'tokens-symbols.properties'
		into "${zipBaseFolder}/lib"
	}

	// Avoid execution by itself
	enabled = false
}

tasks.register('dist', Zip) {
	dependsOn tasks.named("processResources"), tasks.named("copyDependencies"), tasks.named("jar"), tasks.named("extractLexerLiterals"), tasks.named("writeResolvedJars"), tasks.named("baseDistZip")

	duplicatesStrategy = DuplicatesStrategy.EXCLUDE

	archiveVersion.set("${project.version}-bin")

	//noinspection GroovyAssignabilityCheck
	with tasks.named("baseDistZip").get()

	from(layout.buildDirectory.file("libs").get().asFile) {
		include 'lib/*.jar', "${project.name}-${project.version}.jar"
		into "${zipBaseFolder}/lib"
	}

}

tasks.register('distStandalone', Zip) {
	dependsOn tasks.named("fatJar"), tasks.named("baseDistZip")

	duplicatesStrategy = DuplicatesStrategy.EXCLUDE

	archiveVersion.set("${project.version}-standalone-bin")

	//noinspection GroovyAssignabilityCheck
	with tasks.named("baseDistZip").get()

	from(layout.buildDirectory.file("libs").get().asFile) {
		include "${project.name}-standalone-${project.version}.jar"
		into "${zipBaseFolder}/lib"
	}
}

tasks.register('compileJmh', JavaCompile) {
	dependsOn tasks.named('generateBenchmarkGrammarSource')
	source = sourceSets.benchmark.java
	classpath = sourceSets.benchmark.compileClasspath
	destinationDirectory = layout.buildDirectory.file("classes/benchmark").get().asFile
	options.annotationProcessorPath = configurations.annotationProcessor
}

tasks.register('runJmh', JavaExec) {
	dependsOn tasks.named("compileJmh")
	mainClass = 'org.openjdk.jmh.Main'
	classpath = files(
			compileJmh.destinationDirectory,
			sourceSets.benchmark.runtimeClasspath,
			sourceSets.main.runtimeClasspath
	)

	// Output directory for benchmark results
	def outputDir = layout.buildDirectory.file("reports/benchmarks").get().asFile
	def resultFileJson = file("$outputDir/jmh-results.json")

	doFirst {
		outputDir.mkdirs()
	}

	// Arguments for JMH
	args = [
			'-rf', 'json',               // result format
			'-rff', resultFileJson.path, // result file for JSON
			'-i', '5',                   // 5 iterations
			'-wi', '3',                  // 3 warmup iterations
			'-f', '1'                    // single fork
	]
}

tasks.withType(Javadoc).configureEach {
	dependsOn tasks.named("generateGrammarSource")
	source = sourceSets.main.allJava
	classpath = sourceSets.main.compileClasspath
	destinationDir = layout.buildDirectory.file("docs/javadoc").get().asFile
	options {
		encoding = 'UTF-8'
		charSet = 'UTF-8'
		memberLevel = JavadocMemberLevel.PRIVATE
		author = true
		version = true
		// Add a window title for the generated docs
		windowTitle = "${project.name} ${project.version} API"
		// Add a doc title on the main page
		docTitle = "${project.name} API Documentation"
		// Show deprecated members in docs
		addBooleanOption('Xdoclint:none', true)  // disables strict lint checks
	}
	options.addStringOption('--enable-preview')
	options.addStringOption('-add-modules', 'jdk.incubator.vector')
}

//TODO: create maven central account
// https://central.sonatype.org/register/central-portal/
// https://central.sonatype.com/
publishing {
	publications {
		mavenJava(MavenPublication) {
			from components.java

			// Optional: add metadata
			pom {
				name = 'Naftah'
				description = 'Naftah Programming Language : Let\'s write programs in Arabic, like living in Naftah'
				url = 'https://github.com/Chakib-DAII/Naftah'
				licenses {
					license {
						name = 'The Apache License, Version 2.0'
						url = 'https://www.apache.org/licenses/LICENSE-2.0.txt'
					}
				}
				developers {
					developer {
						id = 'yourid'
						name = 'Your Name'
						email = 'you@example.com'
					}
				}
				scm {
					connection = 'scm:git:git://github.com/yourusername/yourlang.git'
					developerConnection = 'scm:git:ssh://github.com/yourusername/yourlang.git'
					url = 'https://github.com/yourusername/yourlang'
				}
			}
		}
	}
	repositories {
		maven {
			name = 'MavenCentral'  // or your repo
			url = 'https://oss.sonatype.org/service/local/staging/deploy/maven2/'  // For Maven Central
			credentials {
				username = project.findProperty("ossrhUsername") ?: System.getenv("OSSRH_USERNAME")
				password = project.findProperty("ossrhPassword") ?: System.getenv("OSSRH_PASSWORD")
			}
		}
	}
}

//TODO: add signing
//export GPG_PRIVATE_KEY=$(gpg --armor --export-secret-keys YOUR_KEY_ID)
//export GPG_PASSPHRASE=yourPassphrase

//signing {
//	// Tell Gradle to sign the Maven publication

//	useInMemoryPgpKeys(
//		System.getenv("GPG_PRIVATE_KEY"),
//		System.getenv("GPG_PASSPHRASE")
//	)
//	sign publishing.publications.mavenJava
//}
